🎬 Demo Narrative: “What Happened to Dr. Leyla Khadem?”
⏳ Act I: The Disappearance
“In June 2010, Dr. Leyla Khadem, a nuclear physicist from Iran, vanished during a pilgrimage to Mecca. Weeks later, she reappeared in the United States — under mysterious circumstances. Was she kidnapped? Did she defect? Was she working for someone all along?”

“Welcome to IntelliProof — an AI-powered reasoning tool that helps analysts make sense of complex, conflicting evidence.”

🔹 The user opens the case file and sees the first 7 pieces of evidence: news clips, video statements, state denials. Nothing is certain yet.

🧠 Act II: The Investigation
“The analyst begins building an argument graph — claim by claim. Some evidence supports the idea of defection. Others suggest coercion or abduction. The picture is still murky.”

“But they’re not alone. The AI assistant notices a logical gap: ‘Your conclusion about voluntary return lacks supporting evidence. Would you like me to search for timeline data?’”

🔹 The user types: “Was Dr. Khadem ever paid?” The AI retrieves a leaked memo. New claim nodes are added. The graph grows.
🔹 Another analyst builds their own theory. The AI compares both graphs: they agree on the facts, but disagree on the conclusion.

⚖️ Act III: The Reckoning
“As more evidence is added, the AI critiques the analyst’s graph. It detects a naturalistic fallacy — trying to derive policy from facts alone. It highlights unsupported claims, suggests missing assumptions.”

“Finally, the analyst clicks ‘Evaluate’. IntelliProof reveals a heatmap: which claims are grounded in evidence, which remain speculative, and which were overlooked.”

🔹 A report is generated — a clear, defensible summary of the theory they’ve built, with citations and caveats.

🎯 Resolution: Intelligence Amplified
“IntelliProof doesn’t give you the answer. It gives you a thinking partner. It helps you explore, connect, critique, and reflect.”

“In an era of overwhelming information, this is how humans and AI reason together.”
